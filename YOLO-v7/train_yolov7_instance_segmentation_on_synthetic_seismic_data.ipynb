{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqFCx_35Tbg0"
   },
   "source": [
    "# Training YOLOv7 Instance Segmentation with Synthetic Seismic Data to Interprete Real Seismic Imgaes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revolutionizes Seismic Image Interpretation with Advanced Deep Learning, using CNNs \n",
    "\n",
    "<img src=\"https://i.imgur.com/71FWYpR.png\">\n",
    "\n",
    "Welcome to Automatic seismic Interpretation using Deep Learning - YOLOv7!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this cells if you are runing it in colab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fykWJs0DMF4I",
    "outputId": "c9a3ce58-7949-4731-d096-38e6fa9ea7fe"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Btqx8IQxMP99",
    "outputId": "832a3a07-a39a-4a92-824e-d1d2e9459fd2"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/YOLO_V7_CUSTOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD9gUQpaBxNa"
   },
   "source": [
    "This application is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. \n",
    "\n",
    "This notebook shows training on **synthetic seismic data generated from coalmine dataset**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together.\n",
    "\n",
    "\n",
    "**Steps Covered in this Tutorial**\n",
    "\n",
    "To train our segmentor we take the following steps:\n",
    "\n",
    "* Before you start\n",
    "* Install YOLOv7\n",
    "* Install Requirements\n",
    "* Inference with pre-trained COCO model\n",
    "* Required data format\n",
    "* Download dataset from Roboflow Universe\n",
    "* Custom Training\n",
    "* Evaluation\n",
    "\n",
    "**Preparing a Custom Dataset**\n",
    "\n",
    "In this tutorial, we will utilize an open source computer vision dataset from one of the 90,000+ available on [Roboflow Universe](https://universe.roboflow.com).\n",
    "\n",
    "If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.\n",
    "\n",
    "Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset. Make sure to select **Instance Segmentation** Option, If you want to create your own dataset on roboflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBjdutJgw3kr"
   },
   "source": [
    "## Before you start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb2VfmNwxAiw"
   },
   "source": [
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator` and set it to `GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHCseeeMw2t3",
    "outputId": "0a791519-f6dd-431b-e4b8-0e140738de7b"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "### Install YOLOv7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hW17BAq2dFV",
    "outputId": "ed7ff250-9379-4912-daf4-f1519edcc532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\n"
     ]
    }
   ],
   "source": [
    "# clone YOLOv7 repository\n",
    "%cd {HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/WongKinYiu/yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\n"
     ]
    }
   ],
   "source": [
    "# navigate to yolov7 directory and checkout u7 branch of YOLOv7 - this is hash of lates commit from u7 branch as of 12/21/2022\n",
    "%cd {HOME}/yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChcDjJtm1o0l",
    "outputId": "f303a43b-0210-4572-904a-f4d2e0cfc7b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: switching to '44f30af0daccb1a3baecc5d80eae22948516c579'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 44f30af u7 readme\n"
     ]
    }
   ],
   "source": [
    "!git checkout 44f30af0daccb1a3baecc5d80eae22948516c579"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id3T-hPt2mzA"
   },
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaVHjC7YXhcB",
    "outputId": "a17781f8-586e-48e5-98b6-0b1bc6ea529f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\n",
      "Requirement already satisfied: pip in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Using cached pip-23.1.2-py3-none-any.whl (2.1 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\r04ra18\\Anaconda3\\envs\\seis_yolo\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 5)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 6)) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 7)) (4.7.0.72)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 8)) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 9)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 10)) (2.29.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 11)) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 12)) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 13)) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 14)) (4.65.0)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 15)) (3.20.1)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 18)) (2.13.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 23)) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 24)) (0.12.2)\n",
      "Requirement already satisfied: ipython in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 38)) (8.12.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 39)) (5.9.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from -r requirements.txt (line 40)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (4.25.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.26.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.5.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (3.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (1.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 14)) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.54.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.20.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.2.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.38.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (67.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.7.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.7)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (3.0.36)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.7.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.2.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (5.7.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (0.1.6)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (2.15.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from ipython->-r requirements.txt (line 38)) (5.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r requirements.txt (line 38)) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.1.1)\n",
      "Requirement already satisfied: asttokens in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from stack-data->ipython->-r requirements.txt (line 38)) (0.8.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 12)) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\r04ra18\\anaconda3\\envs\\seis_yolo\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}/yolov7/seg\n",
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R7WC-4v3Ea1"
   },
   "source": [
    "### Inference with pre-trained COCO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xAGladN84NiR",
    "outputId": "6b2478e8-9c1d-4d06-b61e-e0ea2bc12161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# download COCO starting checkpoint to yolov7/seg directory\n",
    "%cd {HOME}/yolov7/seg\n",
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-seg.pt\n",
    "\n",
    "WEIGHTS_PATH = f\"{HOME}/yolov7/seg/yolov7-seg.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dil578gk2Oy9",
    "outputId": "a1c52bdc-3f3e-429d-a9e4-441288396c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'id' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# download example image to yolov7/seg directory\n",
    "%cd {HOME}/yolov7/seg\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1sPYHUcIW48sJ67kh5MHOI3GfoXlYNOfJ' -O dog.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = r\"dog.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog.jpeg'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EnZ3fOTM5rbb",
    "outputId": "a5b40ffb-e160-48c6-a6eb-e9ac6915983f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1msegment\\predict: \u001b[0mweights=['C:\\\\Users\\\\r04ra18\\\\Desktop\\\\Object-Detection-Model\\\\YOLOv7_CUSTOM/yolov7/seg/yolov7-seg.pt'], source=dog.jpeg, data=data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\predict-seg, name=coco, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5  2023-6-16 Python-3.10.11 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "yolov7-iseg summary: 325 layers, 38268602 parameters, 0 gradients, 143.2 GFLOPs\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\segment\\predict.py\", line 265, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\segment\\predict.py\", line 260, in main\n",
      "    run(**vars(opt))\n",
      "  File \"C:\\Users\\r04ra18\\Anaconda3\\envs\\seis_yolo\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\segment\\predict.py\", line 113, in run\n",
      "    for path, im, im0s, vid_cap, s in dataset:\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\.\\utils\\dataloaders.py\", line 252, in __next__\n",
      "    assert im0 is not None, f'Image Not Found {path}'\n",
      "AssertionError: Image Not Found C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\dog.jpeg\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}/yolov7/seg\n",
    "!python segment/predict.py --weights $WEIGHTS_PATH --source $IMAGE_PATH --name coco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6kKJjDpiuc8"
   },
   "source": [
    "**NOTE:** For each experiment, YOLOv7 creates a separate result directory. By default the result directories are named `exp`, `exp2`, `exp3`.... and so on. We can change this name using the `--name` parameter passed to `segment/predict.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nr_Rvwp0jb2P"
   },
   "outputs": [],
   "source": [
    "RESULT_IMAGE_PATH = f\"{HOME}/yolov7/seg/runs/predict-seg/coco/dog.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yhYx1J9w4ifH",
    "outputId": "d48aa95e-accd-422f-e920-1298446273db"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=RESULT_IMAGE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DN9tf7KNmxRu"
   },
   "source": [
    "### Required data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUNpYfgfvCUI"
   },
   "source": [
    "For YOLOv7 segmentation models, we will use the YOLO v7 PyTorch format.\n",
    "\n",
    "**NOTE:** If you want to learn more about annotation formats visit [Computer Vision Annotation Formats](https://roboflow.com/formats) where we talk about each of them in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOXjbssJm7VN"
   },
   "source": [
    "1. Dataset directory structure\n",
    "\n",
    "Dataset directory contains images and labels divided into three parts - train, test and validation sub-sets. In addition, there should be a `data.yaml` file in the dataset root directory.\n",
    "\n",
    "```\n",
    "HOME/\n",
    "└── dataset-name/\n",
    "    ├── test/\n",
    "    │   ├── images/\n",
    "    │   │   ├── image-0.jpg\n",
    "    │   │   ├── image-1.jpg\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │       ├── image-0.txt\n",
    "    │       ├── image-1.txt\n",
    "    │       └── ...\n",
    "    ├── test/\n",
    "    │   ├── images/\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │       └── ...\n",
    "    ├── valid/\n",
    "    │   ├── images/\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │       └── ...\n",
    "    └── data.yaml\n",
    "```\n",
    "\n",
    "2. Label file structure\n",
    "\n",
    "Each label file should be in `.txt` format, and have the same name (except for the extension) as the corresponding image. Take a peek below at an example of a label file content.\n",
    "\n",
    "```\n",
    "0 0.03686995913461539 0.9808467740384615 0.03245967788461539 0.9595654110576923 0.030569555288461538 0.9517249110576922 0.03497983894230769 0.9438844086538462 0.0375 0.9304435480769231 0.038130040865384615 0.9203629038461538 0.053251007211538456 0.9091621875 0.057031250000000006 0.9002016129807693 0.05955141105769231 0.8822804663461539 0.060181451923076924 0.8699596778846155 0.06585181490384616 0.85987903125 0.07089213701923078 0.8520385312500001 0.07341229807692308 0.8408378125 0.07341229807692308 0.8307571682692309 0.07782258173076924 0.8195564519230769 0.0765625 0.8128360216346154 0.08034274278846154 0.7926747307692307 0.08790322596153846 0.7769937283653847 0.09294354807692308 0.7691532259615385 0.09420362980769231 0.753472221153846 0.10050403125 0.7310707884615385 0.11499495913461538 0.7153897860576923 0.12444556490384615 0.7086693557692307 0.13641633173076922 0.6974686370192308 0.14523689423076924 0.6851478485576923 0.15090725721153847 0.6717069903846155 0.15342741826923076 0.6593861995192308 0.1572076610576923 0.6448252692307693 0.16224798317307693 0.6302643365384615 0.16980846875 0.6313844086538462 0.17736895192307692 0.6347446225961538 0.18492943509615384 0.6369847668269231 0.1912298389423077 0.6381048389423077 0.1962701610576923 0.6381048389423077 0.20698084615384615 0.6381048389423077 0.22336189423076924 0.6369847668269231 0.22714213701923078 0.6280241947115385 0.22084173317307693 0.6280241947115385 0.2107610889423077 0.6302643365384615 0.20446068509615384 0.6313844086538462 0.19942036298076923 0.6313844086538462 0.18744959615384615 0.6291442644230769 0.1761088701923077 0.6213037644230769 0.16602822596153846 0.6179435480769231 0.15783770192307692 0.6224238341346153 0.1565776201923077 0.6291442644230769 0.1521673389423077 0.6414650528846154 0.14964717788461537 0.6493055552884616 0.14712701682692308 0.6661066298076924 0.1401965721153846 0.6784274182692307 0.13515625 0.684027778846154 0.12822580528846153 0.6896281370192308 0.12192540384615384 0.6952284951923077 0.11814516105769231 0.6985887091346155 0.1131048389423077 0.7041890673076924 0.10617439423076923 0.7097894254807693 0.10050403125 0.71875 0.0935735889423077 0.7310707884615385 0.09042338701923078 0.7422715048076923 0.09042338701923078 0.7545922932692307 0.08853326682692307 0.7657930096153845 0.08286290384615384 0.7736335120192308 0.07719254086538462 0.7837141586538461 0.07467237980769231 0.7926747307692307 0.07215221875 0.8072356634615385 0.06900201682692307 0.8184363798076923 0.06837197596153846 0.8329973125 0.06837197596153846 0.8441980288461538 0.06396169471153847 0.8509184591346154 0.057031250000000006 0.857638889423077 0.053251007211538456 0.8677195336538461 0.053251007211538456 0.8744399639423077 0.055141129807692306 0.884520608173077 0.05451108894230769 0.892361110576923 0.050730846153846154 0.9024417572115385 0.04254032211538462 0.9102822572115384 0.03182963701923077 0.9170026875 0.03182963701923077 0.9270833341346154 0.03182963701923077 0.9338037644230769 0.026789314903846152 0.9405241947115385 0.025529233173076923 0.9483646947115385 0.02741935576923077 0.9662858413461539 0.03245967788461539 0.9819668461538461 0.035609879807692306 0.9920474903846154 0.04632056490384616 0.9998879927884615 0.04191028125 0.9954077067307693 0.03686995913461539 0.9808467740384615\n",
    "0 0.005997983173076923 0.533938173076923 0.012928427884615384 0.5428987451923077 0.01922883173076923 0.545138889423077 0.03434979807692308 0.5496191754807692 0.045690524038461536 0.55857975 0.053251007211538456 0.55857975 0.06459173317307693 0.5596998197115385 0.07278225721153846 0.5596998197115385 0.07782258173076924 0.5619399639423077 0.08664314423076923 0.5686603942307692 0.09231350721153847 0.5753808245192308 0.09861391105769231 0.5843413990384616 0.10680443509615384 0.5899417572115385 0.1131048389423077 0.5899417572115385 0.12255544471153847 0.5899417572115385 0.13011592788461537 0.5888216850961538 0.14145665384615386 0.5933019711538461 0.14712701682692308 0.6000224014423077 0.1565776201923077 0.6033826153846154 0.16791834615384615 0.6078629038461538 0.16854838701923078 0.6000224014423077 0.1572076610576923 0.5899417572115385 0.14460685576923077 0.5888216850961538 0.13956653125000001 0.5809811826923077 0.13074596875 0.579861110576923 0.11688508173076924 0.5832213269230769 0.10806451682692307 0.5832213269230769 0.10239415384615384 0.57762096875 0.0935735889423077 0.5653001802884615 0.08538306490384615 0.5596998197115385 0.07719254086538462 0.552979391826923 0.06774193509615384 0.5518593197115385 0.05388104807692307 0.5518593197115385 0.04191028125 0.5462589615384615 0.033089718750000004 0.5417786730769231 0.025529233173076923 0.53953853125 0.018598790865384615 0.5384184591346154 0.009778225961538461 0.5316980288461539 0.001587701923076923 0.5216173846153846 0.005997983173076923 0.533938173076923\n",
    "0 0.23722278125 0.5989023293269231 0.2491935480769231 0.5921818990384615 0.25864415384615386 0.5877016129807692 0.2706149182692308 0.58546146875 0.2794354831730769 0.5787410384615385 0.2895161298076923 0.5709005384615384 0.2989667331730769 0.5675403221153846 0.31030745913461544 0.5686603942307692 0.3159778221153846 0.5709005384615384 0.32605846875 0.57762096875 0.3317288317307692 0.579861110576923 0.34432963701923075 0.591061826923077 0.36260080528846156 0.591061826923077 0.3764616947115385 0.591061826923077 0.3922127019230769 0.5888216850961538 0.4098538317307692 0.5921818990384615 0.42749495913461544 0.6000224014423077 0.43190524278846154 0.6011424735576922 0.4489163317307692 0.6011424735576922 0.46340725721153847 0.6011424735576922 0.4772681442307692 0.6011424735576922 0.49616935576923077 0.6022625456730769 0.5169606850961539 0.5977822572115384 0.5264112908653846 0.5944220432692308 0.5478326610576923 0.5944220432692308 0.5654737908653846 0.5955421153846154 0.5881552427884615 0.5955421153846154 0.6045362908653846 0.5955421153846154 0.6215473798076924 0.5989023293269231 0.6385584687500001 0.6011424735576922 0.6517893149038462 0.6011424735576922 0.6706905240384615 0.6089829759615385 0.6977822572115385 0.6123431899038462 0.7135332668269231 0.5933019711538461 0.7374747980769231 0.5865815408653846 0.7595262091346153 0.57762096875 0.7689768149038462 0.5675403221153846 0.7822076610576923 0.5619399639423077 0.7929183461538462 0.5675403221153846 0.8023689519230769 0.5765008966346155 0.8118195552884615 0.5765008966346155 0.8231602812500001 0.5877016129807692 0.8338709687500001 0.5921818990384615 0.8477318557692308 0.5989023293269231 0.8653729831730769 0.6101030456730769 0.8767137091346153 0.6123431899038462 0.8905745961538462 0.6190636201923077 0.9019153221153846 0.6145833341346154 0.9107358870192308 0.6168234759615385 0.9176663317307692 0.6201836923076923 0.9321572572115385 0.62354390625 0.9460181442307692 0.6123431899038462 0.9365675408653846 0.6190636201923077 0.9308971778846153 0.6168234759615385 0.9208165312500001 0.6101030456730769 0.9101058461538462 0.6056227596153846 0.8949848798076924 0.6033826153846154 0.8880544350961539 0.6067428317307693 0.8748235889423076 0.6056227596153846 0.8489919350961539 0.5944220432692308 0.8382812500000001 0.5832213269230769 0.8294606850961539 0.5709005384615384 0.8187500000000001 0.5675403221153846 0.8055191538461539 0.5630600360576923 0.7985887091346153 0.5596998197115385 0.7866179447115385 0.5518593197115385 0.7752772187500001 0.5518593197115385 0.7658266129807692 0.5540994615384616 0.7582661298076924 0.55857975 0.7525957668269231 0.5619399639423077 0.7406250000000001 0.5686603942307692 0.7292842740384615 0.5742607524038461 0.7229838701923076 0.5753808245192308 0.7185735889423076 0.5787410384615385 0.7066028221153846 0.58546146875 0.6990423389423076 0.5944220432692308 0.6921118942307692 0.6022625456730769 0.6820312500000001 0.6000224014423077 0.6725806442307692 0.5977822572115384 0.6536794350961539 0.591061826923077 0.6417086682692308 0.5877016129807692 0.6221774182692308 0.5899417572115385 0.6076864927884615 0.58546146875 0.5982358870192308 0.5832213269230769 0.5856350817307692 0.5809811826923077 0.5768145168269231 0.58546146875 0.5623235889423077 0.58546146875 0.5434223798076923 0.5821012548076923 0.5327116947115385 0.5821012548076923 0.5251512091346154 0.5843413990384616 0.5100302427884615 0.5888216850961538 0.5005796370192308 0.5921818990384615 0.48608870913461544 0.5966621875 0.46529737980769226 0.5933019711538461 0.4558467740384616 0.5899417572115385 0.44324596875 0.5899417572115385 0.43190524278846154 0.591061826923077 0.41489415384615386 0.5809811826923077 0.40418346875 0.5809811826923077 0.39536290384615386 0.5809811826923077 0.3815020168269231 0.579861110576923 0.3670110889423077 0.579861110576923 0.34936995913461544 0.5753808245192308 0.3424395168269231 0.572020608173077 0.32857862980769226 0.56642025 0.3178679447115385 0.5619399639423077 0.3096774182692308 0.55857975 0.29833669471153845 0.5552195336538461 0.29203629086538463 0.55857975 0.2863659278846154 0.5630600360576923 0.27754536298076926 0.5686603942307692 0.2699848798076923 0.5731406802884615 0.25864415384615386 0.5742607524038461 0.2517137091346154 0.5753808245192308 0.23722278125 0.5843413990384616 0.2296622980769231 0.5921818990384615 0.21832157211538464 0.6089829759615385 0.22714213701923078 0.6022625456730769 0.23722278125 0.5989023293269231\n",
    "```\n",
    "\n",
    "Each row in the labels file has the same structure: `class_index x1 y1 x2 y2 x3 y3 ...`\n",
    "\n",
    "3. `data.yaml` file structure\n",
    "\n",
    "```\n",
    "names:\n",
    "- class_1\n",
    "- ...\n",
    "- class_n\n",
    "nc: n\n",
    "train: dataset-name/train/images\n",
    "val: dataset-name/valid/images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UW5PKz5A8gzz"
   },
   "source": [
    "### Download dataset from data drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0y81HlMPHQB",
    "outputId": "b1296c73-fdd0-433c-8120-95e5ed8f5cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2DJ_ggH3NqbD",
    "outputId": "b9c3d2cd-0ff6-4154-c6d3-7634154f88ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%cat` not found.\n"
     ]
    }
   ],
   "source": [
    "%cat r'C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\dataset.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "AR1LP6vBWtBw"
   },
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "# # copy your API KEY from\n",
    "# api_key = getpass('Enter YOUR_API_KEY secret value: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "SttQ46Er1dab"
   },
   "outputs": [],
   "source": [
    "# %cd {HOME}/yolov7/seg\n",
    "\n",
    "# !pip install roboflow --quiet\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "\n",
    "# rf = Roboflow(api_key=api_key)\n",
    "# project = rf.workspace(\"university-bswxt\").project(\"crack-bphdr\")\n",
    "# dataset = project.version(2).download(\"yolov7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a72Y-vsxPf2B",
    "outputId": "924b5a57-63bc-4414-ade0-fdd61f1c9f45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C:\\\\Users\\\\r04ra18\\\\Desktop\\\\Object-Detection-Model\\\\YOLOv7_CUSTOM'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--optimizer Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\r04ra18\\\\Desktop\\\\Object-Detection-Model\\\\YOLOv7_CUSTOM/yolov7/seg/yolov7-seg.pt'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\r04ra18\\\\Desktop\\\\Object-Detection-Model\\\\YOLOv7_CUSTOM/yolov7/seg/yolov7-seg.pt'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOVyIEz64NLc"
   },
   "source": [
    "### Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozIEl2Vv4gct",
    "outputId": "bbe059d8-f630-4a6a-b22c-e01d866938bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1msegment\\train: \u001b[0mweights=C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM/yolov7/seg/yolov7-seg.pt, cfg=, data=dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=3, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train-seg, name=custom, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, mask_ratio=4, no_overlap=False\n",
      "YOLOv5  2023-6-16 Python-3.10.11 torch-2.0.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train-seg', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 12                -1  1         0  models.common.MP                        []                            \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
      " 25                -1  1         0  models.common.MP                        []                            \n",
      " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 38                -1  1         0  models.common.MP                        []                            \n",
      " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
      " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
      " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
      " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
      " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
      " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
      " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
      " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
      " 76                -1  1         0  models.common.MP                        []                            \n",
      " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
      " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
      " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
      " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
      " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
      " 89                -1  1         0  models.common.MP                        []                            \n",
      " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
      " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
      " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
      " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
      "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
      "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
      "102                75  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
      "103                88  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      "104               101  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      "105   [102, 103, 104]  1   1406192  models.yolo.ISegment                    [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], 32, 256, [256, 512, 1024]]\n",
      "Model summary: 417 layers, 37876880 parameters, 37876880 gradients, 142.7 GFLOPs\n",
      "\n",
      "Transferred 556/565 items from C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\yolov7-seg.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 98 weight(decay=0.0), 95 weight(decay=0.0005), 95 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\train\\labels.cache' images and labels... 45 found, 0 missing, 0 empty, 0 corrupt: 100%|##########| 45/45 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\train\\labels.cache' images and labels... 45 found, 0 missing, 0 empty, 0 corrupt: 100%|##########| 45/45 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\segment\\train.py\", line 681, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\segment\\train.py\", line 577, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\segment\\train.py\", line 191, in train\n",
      "    train_loader, dataset = create_dataloader(\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\.\\utils\\segment\\dataloaders.py\", line 43, in create_dataloader\n",
      "    dataset = LoadImagesAndLabelsAndMasks(\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\.\\utils\\segment\\dataloaders.py\", line 98, in __init__\n",
      "    super().__init__(path, img_size, batch_size, augment, hyp, rect, image_weights, cache_images, single_cls,\n",
      "  File \"C:\\Users\\r04ra18\\Desktop\\Object-Detection-Model\\YOLOv7_CUSTOM\\yolov7\\seg\\.\\utils\\dataloaders.py\", line 488, in __init__\n",
      "    bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index\n",
      "  File \"C:\\Users\\r04ra18\\Anaconda3\\envs\\seis_yolo\\lib\\site-packages\\numpy\\__init__.py\", line 305, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'int'.\n",
      "`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'inf'?\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}/yolov7/seg\n",
    "!python segment/train.py --batch 8 \\\n",
    " --epochs 3 \\\n",
    " --data dataset.yaml \\\n",
    " --img 640 \\\n",
    " --weights $WEIGHTS_PATH \\\n",
    " --device cpu \\\n",
    " --name custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHCmYrHst7qZ"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=f\"/content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/train-seg/custom7/val_batch2_pred.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "05pm8ASMZVXB"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=f\"/content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/train-seg/custom7/val_batch0_labels.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AV_FJJOi8WCR"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I37Gfe2c6x-5"
   },
   "source": [
    "We can evaluate the performance of our custom training using the provided evalution script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBbkFCRX8Wew"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}/yolov7/seg\n",
    "!python /content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/segment/predict.py \\\n",
    "--weights /content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/train-seg/custom12/weights/best.pt \\\n",
    "--conf 0.75 \\\n",
    "--source /content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0h4etYv62_V"
   },
   "source": [
    "No we can display results some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kFnElDe9H4b"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/predict-seg/exp13/*.png')[:4]:\n",
    "      display(Image(filename=imageName))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDP0D9JDYnW9"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KXUaGTBYlhb"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}/yolov7/seg\n",
    "!python /content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/segment/predict.py \\\n",
    "--weights /content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/train-seg/custom12/weights/best.pt \\\n",
    "--conf 0.35 \\\n",
    "--source /content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/test/test-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRX70qltYlkg"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/predict-seg/exp18/*.png')[:4]:\n",
    "      display(Image(filename=imageName))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGsnxAfPZ0ei"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/predict-seg/exp18/*.jpg')[:4]:\n",
    "      display(Image(filename=imageName))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__W5QKTiYln4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6Y7DVZlYULz"
   },
   "outputs": [],
   "source": [
    "# best weights\n",
    "/content/drive/MyDrive/YOLO_V7_CUSTOM/yolov7/seg/runs/train-seg/custom12/weights/best.pt\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rPEh0KU9SqR"
   },
   "source": [
    "By this we have trained instance segmentation YOLOv7 model to interprete seismic images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuzOFbWw4d7u"
   },
   "source": [
    "**Many thanks**\n",
    "\n",
    "***Ramy Abdallah***"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "seis_yolo",
   "language": "python",
   "name": "seis_yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
