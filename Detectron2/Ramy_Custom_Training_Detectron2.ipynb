{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilising Detectron2 to perform fast automated structural analysis for seismic sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tq9-5ng815OG"
   },
   "source": [
    "## Revolutionizes Seismic Image Interpretation with Advanced Deep Learning, using CNNs \n",
    "\n",
    "<img src=\"https://i.imgur.com/wY8BOfV.jpg\" width=\"500\">\n",
    "\n",
    "Welcome to Automatic seismic Interpretation using Deep Learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zBk663LIPj1",
    "outputId": "2d0d42d0-8897-4e16-f0bf-5ae35cc70da4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLujkHpp2MLH"
   },
   "source": [
    "# Install Detectron2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The !nvidia-smi command is used to query and display information about the NVIDIA GPU(s) available on your system. To utilize this command in a Jupyter Notebook, simply include ! before the command, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCb6hpdwIXJp",
    "outputId": "1638fcbd-9430-4878-b5a9-27b042a8aad4"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When executed, this command will output real-time details about the GPU(s), including usage statistics, memory information, temperature, and more. This information is valuable for monitoring GPU performance and can be beneficial when optimizing code for GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRgS8WcPI-7c",
    "outputId": "a7c30b65-c1b4-4610-fe03-2183aa33110a"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/detecron2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%cd /content/drive/MyDrive/detecron2` command in Jupyter Notebooks is utilized to set the current working directory to \"/content/drive/MyDrive/detecron2\". Adjust this path according to the location of your Detectron2 project. Ensuring the correct working directory is crucial for seamless code execution and resource access within the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwT7yQ5g2SW1",
    "outputId": "3704f688-5a7e-4740-e5eb-e3a084201a96"
   },
   "outputs": [],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# Properly install detectron2. (Please do not install twice in both ways)\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "doohaKg-IhvQ",
    "outputId": "94b2280c-f904-494f-e111-f3fe91adc75f"
   },
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Detectron2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet sets up the environment for using Detectron2, a popular computer vision library for object detection. It includes the following steps:\n",
    "\n",
    "Setting up Detectron2 Logger: Initializes the logger for Detectron2 to handle logging.\n",
    "Importing Common Libraries: Imports essential libraries like NumPy, OpenCV (cv2), and tools for displaying images in Google Colab.\n",
    "Importing Detectron2 Utilities: Imports necessary modules from Detectron2, including model zoo, predictor, configuration, visualizer, and data utilities.\n",
    "This code is a foundational setup for subsequent tasks involving Detectron2, such as configuring models, loading datasets, and performing object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6vvZwwKhIk8t"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9FxnsUs2SNT"
   },
   "outputs": [],
   "source": [
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOfAjDrzI7in",
    "outputId": "8f58d64f-be28-4231-89ea-4601761c6a5b"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1dNZif9N7Nu",
    "outputId": "8b475511-0532-4734-e9fc-11ed5eeb978b"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/detecron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvRBLqNV2SKX"
   },
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"customtrain\", {}, \"./trainval.json\", \"./images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOPu91aP2SHf",
    "outputId": "6c74a49f-3856-4cb1-8b63-fd85a6e4b19b"
   },
   "outputs": [],
   "source": [
    "sample_metadata = MetadataCatalog.get(\"customtrain\")\n",
    "dataset_dicts = DatasetCatalog.get(\"customtrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `import random`: Imports the `random` module for generating random samples.\n",
    "\n",
    "2. `for d in random.sample(dataset_dicts, 5):`:\n",
    "   - Iterates over five random samples from `dataset_dicts`, assuming it's a list of dictionaries representing a dataset.\n",
    "\n",
    "3. `img = cv2.imread(d[\"file_name\"])`:\n",
    "   - Reads the image file specified by the \"file_name\" key in the current dataset dictionary (`d`) using OpenCV (`cv2`).\n",
    "\n",
    "4. `visualizer = Visualizer(img[:, :, ::-1], metadata=sample_metadata, scale=0.5)`:\n",
    "   - Creates a `Visualizer` object to visualize the image.\n",
    "   - The `metadata` parameter is assumed to contain metadata for visualization.\n",
    "   - The `scale` parameter sets the scale of the visualization to 0.5.\n",
    "\n",
    "5. `vis = visualizer.draw_dataset_dict(d)`:\n",
    "   - Uses the `Visualizer` to draw bounding boxes and annotations on the image based on the information in the current dataset dictionary (`d`).\n",
    "\n",
    "6. `cv2_imshow(vis.get_image()[:, :, ::-1])`:\n",
    "   - Displays the visualized image using `cv2_imshow`, which is a Google Colab-specific function for showing images.\n",
    "   - The `[:, :, ::-1]` part reverses the order of color channels to match the expected format for image display.\n",
    "\n",
    "Overall, the code randomly selects five samples from a dataset (`dataset_dicts`), reads and visualizes the corresponding images, including any annotations or bounding boxes, and displays them using the `cv2_imshow` function in a Google Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CElnA6-32SEe",
    "outputId": "78f5b6a7-ef17-468a-d274-92bcdfdbb0b4"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for d in random.sample(dataset_dicts, 5):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=sample_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration for training a Mask R-CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `from detectron2.engine import DefaultTrainer`: Imports the `DefaultTrainer` class from the Detectron2 engine module.\n",
    "\n",
    "2. `cfg = get_cfg()`: Initializes a Detectron2 configuration (`cfg`) using `get_cfg()`.\n",
    "\n",
    "3. `cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))`:\n",
    "   - Merges the configuration settings from the COCO instance segmentation model configuration file (`mask_rcnn_R_50_FPN_3x.yaml`) into the current configuration.\n",
    "\n",
    "4. `cfg.DATASETS.TRAIN = (\"customtrain\",)`: Specifies the training dataset, assumed to be named \"customtrain\".\n",
    "\n",
    "5. `cfg.DATASETS.TEST = ()`: Specifies that no separate test dataset is used.\n",
    "\n",
    "6. `cfg.DATALOADER.NUM_WORKERS = 2`: Sets the number of data loader workers to 2 for parallel data loading.\n",
    "\n",
    "7. `cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")`:\n",
    "   - Initializes the model weights from the COCO instance segmentation model available in the model zoo.\n",
    "\n",
    "8. `cfg.SOLVER.IMS_PER_BATCH = 8`: Sets the number of images per batch during training to 8.\n",
    "\n",
    "9. `cfg.SOLVER.BASE_LR = 0.0025`: Sets the base learning rate for the optimizer.\n",
    "\n",
    "10. `cfg.SOLVER.MAX_ITER = 3200`: Sets the maximum number of training iterations to 3200.\n",
    "\n",
    "11. `cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 640`: Sets the batch size per image for region of interest (ROI) heads to 640.\n",
    "\n",
    "12. `cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3`: Specifies the number of classes in the dataset, assumed to be 3.\n",
    "\n",
    "13. `os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)`: Creates the output directory specified in the configuration if it does not exist.\n",
    "\n",
    "14. `trainer = DefaultTrainer(cfg)`: Initializes a `DefaultTrainer` object with the provided configuration.\n",
    "\n",
    "15. `trainer.resume_or_load(resume=False)`: Resumes training from a checkpoint if available or loads the pre-trained weights.\n",
    "\n",
    "16. `trainer.train()`: Initiates the training process using the specified configuration.\n",
    "\n",
    "In summary, the code sets up a configuration for training a Mask R-CNN model on a custom dataset, configures various parameters such as batch size and learning rate, and then starts the training process using the `DefaultTrainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOpKgegl2SBz",
    "outputId": "37f82335-5cc0-4fc0-eee6-01a6665f5cfd"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"customtrain\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8 # 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 3200 # 1200    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 640 # 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Model Inference for Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Setting Model Weights Path:**\n",
    "   - `cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")`: Specifies the path to the final trained model weights generated during the training process. This ensures that the inference uses the latest model state.\n",
    "\n",
    "2. **Setting Inference Threshold:**\n",
    "   - `cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5`: Establishes a threshold for object detection during testing. Objects with confidence scores below this threshold are not considered during inference.\n",
    "\n",
    "3. **Setting Test Dataset:**\n",
    "   - `cfg.DATASETS.TEST = (\"customtrain\", )`: Defines the dataset (assumed to be named \"customtrain\") to be used for model testing. This ensures that the model is evaluated on the specified dataset during inference.\n",
    "\n",
    "4. **Initializing Predictor:**\n",
    "   - `predictor = DefaultPredictor(cfg)`: Creates an instance of the `DefaultPredictor` class with the configured settings. The `DefaultPredictor` is a convenient wrapper that simplifies the process of making predictions using a trained Detectron2 model.\n",
    "\n",
    "In summary, this code segment prepares the Mask R-CNN model for inference on a custom dataset by specifying the model weights, setting a confidence threshold for object detection, defining the test dataset, and initializing a predictor for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drR2t1tm5LjP",
    "outputId": "d2d15105-4ce7-4350-be38-7f911b89a101"
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"customtrain\", )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Visualizing Model Predictions on Random Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code snippet is responsible for visualizing the predictions made by a Mask R-CNN model on a few randomly selected samples from a dataset. Below is an explanation of the key components:\n",
    "\n",
    "1. **Model Prediction:**\n",
    "   - `outputs = predictor(im)`: Uses the previously configured predictor to obtain model predictions on the input image (`im`).\n",
    "\n",
    "2. **Visualization Settings:**\n",
    "   - `v = Visualizer(im[:, :, ::-1], metadata=sample_metadata, scale=0.8, instance_mode=ColorMode.IMAGE_BW)`: Initializes a visualizer (`v`) with the input image, metadata, and visualization settings. The `ColorMode.IMAGE_BW` parameter is set to remove colors from unsegmented pixels.\n",
    "\n",
    "3. **Drawing Predictions:**\n",
    "   - `v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))`: Draws the instance predictions (bounding boxes, masks, etc.) on the visualizer. The predictions are obtained from the model's output and converted to CPU format for visualization.\n",
    "\n",
    "4. **Displaying Visualization:**\n",
    "   - `cv2_imshow(v.get_image()[:, :, ::-1])`: Displays the final visualized image using OpenCV. The image is converted to the RGB format for proper display.\n",
    "\n",
    "In summary, this code segment generates visualizations for model predictions on a few randomly selected images from the dataset. The visualizations include bounding boxes, masks, and other instance-level information predicted by the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WFSAaVYH2R-W",
    "outputId": "cfe3f06e-1c47-44ec-ddd7-dad08616446d"
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "for d in random.sample(dataset_dicts, 4):\n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=sample_metadata,\n",
    "                   scale=0.8,\n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Model Predictions on a Single Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Read Image:**\n",
    "   - `im = cv2.imread(\"/content/drive/MyDrive/detecron2/images/acoustic_impedance__Section_5_Ems.png\")`: Reads the specified image file using OpenCV and stores it in the variable `im`.\n",
    "\n",
    "2. **Model Prediction:**\n",
    "   - `outputs = predictor(im)`: Utilizes the predictor to obtain model predictions on the input image (`im`).\n",
    "\n",
    "3. **Visualization Settings:**\n",
    "   - `v = Visualizer(im[:, :, ::-1], metadata=sample_metadata, scale=0.8, instance_mode=ColorMode.IMAGE_BW)`: Initializes a visualizer (`v`) with the input image, metadata, and visualization settings. The `ColorMode.IMAGE_BW` parameter is set to remove colors from unsegmented pixels.\n",
    "\n",
    "4. **Drawing Predictions:**\n",
    "   - `v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))`: Draws the instance predictions (bounding boxes, masks, etc.) on the visualizer. The predictions are obtained from the model's output and converted to CPU format for visualization.\n",
    "\n",
    "5. **Displaying Visualization:**\n",
    "   - `cv2_imshow(v.get_image()[:, :, ::-1])`: Displays the final visualized image using OpenCV. The image is converted to the RGB format for proper display.\n",
    "\n",
    "In summary, this code segment visualizes the predictions made by a Mask R-CNN model on a specific image, showing bounding boxes, masks, and other instance-level details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "wMVaHPnGa_L3",
    "outputId": "54e0b39f-80d2-4bc6-b9c5-f1df8e3b3759"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/images/acoustic_impedance__Section_5_Ems.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "8hCC_3xCbnId",
    "outputId": "6ab3c26b-e70a-4408-cf61-847985698e44"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/images/acoustic_impedance__Section_8_Ems.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "ktBdO6cNbnM8",
    "outputId": "b9865024-4dfd-420d-a0b8-93a930b52acc"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/images/acoustic_impedance__Section_9_Ems.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "FxHFvxxmbyJV",
    "outputId": "990e0a4a-2b9f-4860-f6a1-c50adf1be42b"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/images/acoustic_impedance__Section_3_Ems.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Loo2ukxDNLer"
   },
   "source": [
    "## Testing from the Coalmine cross-sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Image File Paths from a Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Import Modules:**\n",
    "   - `import os`: Imports the Python module for interacting with the operating system.\n",
    "   - `from os import listdir`: Imports the `listdir` function from the `os` module.\n",
    "\n",
    "2. **Specify Directory and Initialize List:**\n",
    "   - `folder_dir = '/content/drive/MyDrive/detecron2/testing-crosssections-images'`: Specifies the directory path where the images are located.\n",
    "   - `images_ls = []`: Initializes an empty list (`images_ls`) to store the file paths of image files.\n",
    "\n",
    "3. **Iterate Through Files in the Directory:**\n",
    "   - `for images in os.listdir(folder_dir):`: Iterates through the files in the specified directory.\n",
    "   - `if (images.endswith(\".png\") or images.endswith(\".jpg\") or images.endswith(\".jpeg\")):`: Checks if the file has one of the specified image file extensions (`.png`, `.jpg`, or `.jpeg`).\n",
    "   - `images_ls.append(folder_dir + \"/\" +  images)`: If the file is an image, appends its complete path to the `images_ls` list.\n",
    "\n",
    "In summary, this code segment creates a list (`images_ls`) containing the full file paths of image files with specific extensions (`png`, `jpg`, and `jpeg`) found within a specified directory (`folder_dir`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydjoWG6WNKDQ"
   },
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "# get the path or directory\n",
    "folder_dir = '/content/drive/MyDrive/detecron2/testing-crosssections-images'\n",
    "images_ls = []\n",
    "for images in os.listdir(folder_dir):\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\\\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        images_ls.append(folder_dir + \"/\" +  images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping Through Images and Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Loop Over Image Paths:**\n",
    "   - `for image_file in images_ls:`: Initiates a loop to iterate over each image file path in the `images_ls` list.\n",
    "\n",
    "2. **Construct Image Path:**\n",
    "   - `image_path = os.path.join(folder_dir, image_file)`: Constructs the full path of the current image by joining the specified directory (`folder_dir`) and the image file name.\n",
    "\n",
    "3. **Read Image and Make Predictions:**\n",
    "   - `im = cv2.imread(image_path)`: Reads the image using OpenCV.\n",
    "   - `outputs = predictor(im)`: Uses the pre-trained model (`predictor`) to make predictions on the current image.\n",
    "\n",
    "4. **Visualize Predictions:**\n",
    "   - `v = Visualizer(im[:, :, ::-1], metadata=sample_metadata, scale=0.8, instance_mode=ColorMode.IMAGE_BW)`: Creates a visualizer object for the current image.\n",
    "   - `v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))`: Draws the predicted instances on the image using the visualizer.\n",
    "\n",
    "5. **Display Image with Predictions:**\n",
    "   - `cv2_imshow(v.get_image()[:, :, ::-1])`: Displays the image with the overlaid predicted instances.\n",
    "\n",
    "This code segment essentially automates the process of loading multiple images, making predictions, and visualizing the results, allowing for a quick inspection of the model's performance on a set of test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "l5b_15TrNKI5",
    "outputId": "0ecaed92-ab07-4d84-e477-7e92f98a3d7d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Loop over the images and predict each one\n",
    "for image_file in images_ls:\n",
    "    image_path = os.path.join(folder_dir, image_file)\n",
    "    im = cv2.imread(image_path)\n",
    "    outputs = predictor(im)\n",
    "\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=sample_metadata,\n",
    "                   scale=0.8,\n",
    "                   instance_mode=ColorMode.IMAGE_BW)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ufY-71JZpRl"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Image Files in a Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code snippet aims to create a list (`images_ls`) containing the file paths of image files (with extensions `.png`, `.jpg`, or `.jpeg`) located in a specified directory (`folder_dir`).\n",
    "\n",
    "1. **Import Necessary Modules:**\n",
    "   - `import os`: Imports the `os` module for operating system-related functions.\n",
    "   - `from os import listdir`: Imports the `listdir` function from the `os` module.\n",
    "\n",
    "2. **Define Directory and Initialize List:**\n",
    "   - `folder_dir = '/content/drive/MyDrive/detecron2/test-images'`: Specifies the directory path where the images are located.\n",
    "   - `images_ls = []`: Initializes an empty list (`images_ls`) to store the file paths of eligible image files.\n",
    "\n",
    "3. **Loop Over Files in the Directory:**\n",
    "   - `for images in os.listdir(folder_dir):`: Initiates a loop to iterate over each file in the specified directory.\n",
    "\n",
    "4. **Filter Image Files:**\n",
    "   - The `if` condition checks whether the file has an extension of `.png`, `.jpg`, or `.jpeg`.\n",
    "   - `images_ls.append(folder_dir + \"/\" + images)`: Appends the full file path to the `images_ls` list for eligible image files.\n",
    "\n",
    "After running this code snippet, the list `images_ls` will contain the full paths of image files in the specified directory, filtered based on the mentioned file extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-03JzkPwiCrU"
   },
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "# get the path or directory\n",
    "folder_dir = '/content/drive/MyDrive/detecron2/test-images'\n",
    "images_ls = []\n",
    "for images in os.listdir(folder_dir):\n",
    "    if (images.endswith(\".png\") or images.endswith(\".jpg\")\\\n",
    "        or images.endswith(\".jpeg\")):\n",
    "        images_ls.append(folder_dir + \"/\" +  images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Image File Paths and Read Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code snippet iterates over the list of image file paths (`images_ls`) and prints each file path. Additionally, there is a commented line to demonstrate reading and printing images using OpenCV.\n",
    "\n",
    "**Code Explanation:**\n",
    "```python\n",
    "# Loop Over Image File Paths\n",
    "for i in range(len(images_ls)):\n",
    "    # Print the Image File Path\n",
    "    print(images_ls[i])\n",
    "    \n",
    "    # Uncomment the line below to Read and Print Images Using OpenCV\n",
    "    # image = cv2.imread(images_ls[i])\n",
    "    # print(image)\n",
    "```\n",
    "\n",
    "- **Loop Over Image File Paths:**\n",
    "  - `for i in range(len(images_ls)):`\n",
    "  - Initiates a loop to iterate over each image file path in the `images_ls` list.\n",
    "\n",
    "- **Print Image File Paths:**\n",
    "  - `print(images_ls[i])`\n",
    "  - Prints the file path of each image.\n",
    "\n",
    "- **Read and Print Images (Commented):**\n",
    "  - The following two lines are commented (prefixed with `#`), but you can uncomment them to read and print images using OpenCV.\n",
    "  - `image = cv2.imread(images_ls[i])`: Reads the image using OpenCV.\n",
    "  - `print(image)`: Prints the image array.\n",
    "\n",
    "**Note:**\n",
    "- Uncomment the lines if you want to read and print the images. This requires the OpenCV library (`cv2`).\n",
    "- The code is currently set to only print the file paths. If you uncomment and run the OpenCV-related lines, it will also read and print the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipLJiLo1odvM",
    "outputId": "03a39790-0e02-4e37-d65a-82c8ee0cb794"
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_ls)):\n",
    "  print(images_ls[i])\n",
    "  # print(cv2.imread(images_ls[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_C404dBvPYq"
   },
   "outputs": [],
   "source": [
    "folder_path = r\"/content/drive/MyDrive/detecron2/test-images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and Visualize Images Using the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code snippet predicts and visualizes images using a trained model. It loops over a list of image file paths (`images_ls`), reads each image using OpenCV, and then uses the trained model (`predictor`) to make predictions. The predictions are visualized using the Detectron2 library's `Visualizer`, and the images with predicted instances are displayed.\n",
    "\n",
    "**Code Explanation:**\n",
    "```python\n",
    "# Loop Over Image File Paths for Prediction and Visualization\n",
    "for image_file in images_ls:\n",
    "    # Construct the Full Image Path\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    \n",
    "    # Read the Image Using OpenCV\n",
    "    im = cv2.imread(image_path)\n",
    "    \n",
    "    # Make Predictions using the Trained Model\n",
    "    outputs = predictor(im)\n",
    "\n",
    "    # Visualize Predictions using the Detectron2 Visualizer\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=sample_metadata,\n",
    "                   scale=0.8,\n",
    "                   instance_mode=ColorMode.IMAGE_BW)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "    # Display the Visualized Image\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
    "```\n",
    "\n",
    "- **Loop Over Image File Paths:**\n",
    "  - `for image_file in images_ls:`\n",
    "  - Initiates a loop to iterate over each image file path in the `images_ls` list.\n",
    "\n",
    "- **Construct Full Image Path:**\n",
    "  - `image_path = os.path.join(folder_path, image_file)`\n",
    "  - Combines the folder path (`folder_path`) with the current image file path to create the full image path.\n",
    "\n",
    "- **Read the Image Using OpenCV:**\n",
    "  - `im = cv2.imread(image_path)`\n",
    "  - Reads the image using OpenCV.\n",
    "\n",
    "- **Make Predictions:**\n",
    "  - `outputs = predictor(im)`\n",
    "  - Uses the trained model (`predictor`) to make predictions on the current image.\n",
    "\n",
    "- **Visualize Predictions Using Detectron2:**\n",
    "  - `v = Visualizer(im[:, :, ::-1], metadata=sample_metadata, scale=0.8, instance_mode=ColorMode.IMAGE_BW)`\n",
    "  - Initializes the Visualizer with the image, metadata, and visualization settings.\n",
    "  - `v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))`\n",
    "  - Draws the predicted instances on the image using the Visualizer.\n",
    "\n",
    "- **Display Visualized Image:**\n",
    "  - `cv2_imshow(v.get_image()[:, :, ::-1])`\n",
    "  - Displays the visualized image with predicted instances.\n",
    "\n",
    "**Note:**\n",
    "- Ensure that the necessary libraries (`detectron2`, `cv2`) are properly installed and imported before running the code.\n",
    "- The code assumes that `folder_path` is defined and contains the images to be predicted and visualized.\n",
    "- Adjustments to the code may be needed based on the specific requirements of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JBevLECzrLvi",
    "outputId": "be74cbb8-589f-447d-d688-ab47b44ef778"
   },
   "outputs": [],
   "source": [
    "# Loop over the images and predict each one\n",
    "for image_file in images_ls:\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    im = cv2.imread(image_path)\n",
    "    outputs = predictor(im)\n",
    "\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=sample_metadata,\n",
    "                   scale=0.8,\n",
    "                   instance_mode=ColorMode.IMAGE_BW)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "snobohdGt5RW",
    "outputId": "6484f341-b5d6-4f84-a530-10b3616ab17b"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/fig-1.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "C2jVVoRkXYLp",
    "outputId": "5fa21309-e209-4e8b-ecba-2df4575a55bb"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/show_picture.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "7H5IE8vKXYPZ",
    "outputId": "37a8e164-5ec9-436e-fbce-c05f7d160a8c"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/verng02_1zoomclean1.jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "GOua5yGWXYTB",
    "outputId": "1a6b1da1-cd20-49e1-ce43-5a021cff07ef"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/200401-inline-comparisons-slider-full-integrity.jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "0Cv6UsPKZXvI",
    "outputId": "e80d0828-cc7a-41e2-ef1a-7c1b2a156460"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/Legacy_stack_before.jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "0N__l3alZXy4",
    "outputId": "1c10018b-3d51-4387-d63c-dbe23678f3b2"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/some-machine-learning-applications-in-seismic-interpretation-hero.jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "rrIR4fPvgFvc",
    "outputId": "82ef040c-9ecb-45f5-c5a4-e227d7bda1a0"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/fig-1.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "id": "eMmQQvl9gFzJ",
    "outputId": "cbd8699d-11f3-4a63-b603-b537a43f015c"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/geoscience_subsurface_imaging_ima_data_after.jpg\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJy3bNtGhGVs"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "kehEJj1TgF2j",
    "outputId": "c904211c-c9df-49fa-945c-bcca7ae3b708"
   },
   "outputs": [],
   "source": [
    "im = cv2.imread(\"/content/drive/MyDrive/detecron2/test-images/seismic_10042019-600x270-c-default.png\")\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1],\n",
    "                metadata=sample_metadata,\n",
    "                scale=0.8,\n",
    "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    ")\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yf8YtB862R7d"
   },
   "source": [
    "### Evaluation\n",
    "We can evaluate its performance using AP metric implemented in COCO API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance on Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet evaluates the performance of a trained model on a validation dataset using the COCOEvaluator from the Detectron2 library. It calculates metrics such as bounding box (bbox) and segmentation (segm) accuracy. The evaluation results are printed, providing insights into the model's performance on the specified validation dataset.\n",
    "\n",
    "**Code Explanation:**\n",
    "```python\n",
    "# Import Necessary Modules\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Create COCO Evaluator\n",
    "evaluator = COCOEvaluator(\"customtrain\", (\"bbox\", \"segm\"), False, output_dir=\"./output/\")\n",
    "\n",
    "# Build Detection Test Loader for Validation Dataset\n",
    "val_loader = build_detection_test_loader(cfg, \"customtrain\")\n",
    "\n",
    "# Perform Inference on Validation Dataset and Print Results\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
    "```\n",
    "\n",
    "- **Create COCO Evaluator:**\n",
    "  - `evaluator = COCOEvaluator(\"customtrain\", (\"bbox\", \"segm\"), False, output_dir=\"./output/\")`\n",
    "  - Initializes a COCOEvaluator for the \"customtrain\" dataset with evaluation metrics including bounding box (`bbox`) and segmentation (`segm`).\n",
    "\n",
    "- **Build Detection Test Loader:**\n",
    "  - `val_loader = build_detection_test_loader(cfg, \"customtrain\")`\n",
    "  - Constructs a detection test loader for the validation dataset (\"customtrain\") using the specified configuration (`cfg`).\n",
    "\n",
    "- **Perform Inference on Validation Dataset:**\n",
    "  - `inference_on_dataset(trainer.model, val_loader, evaluator)`\n",
    "  - Executes inference on the validation dataset using the trained model (`trainer.model`) and the created evaluator.\n",
    "  - The results include metrics such as AP (average precision) for bounding box and segmentation tasks.\n",
    "\n",
    "- **Print Evaluation Results:**\n",
    "  - `print(...)`\n",
    "  - Prints the evaluation results, providing insights into the model's performance on the specified validation dataset.\n",
    "\n",
    "**Note:**\n",
    "- Ensure that the necessary libraries (`detectron2`) are properly installed and imported before running the code.\n",
    "- Adjustments to the code may be needed based on the specific configurations and datasets used in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eN_EuHXd2R5A",
    "outputId": "bf94039d-4256-4daa-cc92-f3969dc18c0d"
   },
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"customtrain\", (\"bbox\", \"segm\"), False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"customtrain\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePRU49hEQegM"
   },
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1RMgXIWtqIM"
   },
   "source": [
    "### Getting the custom config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCRQHxCz2R1i"
   },
   "outputs": [],
   "source": [
    "f = open('config.yml', 'w')\n",
    "f.write(cfg.dump())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By: Ramy Abdallah "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you!!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
